60ea11e9fed86d4ccaed270c2425c0d9a8cc06e91ac743e9a78277f3535c1239.req 692
b4d6e60a9b97e7b98c63df9308728c5c88c0b40c398046772c63447b94608b4d
Server Address: us-central1-aiplatform.googleapis.com
Port: 443
Protocol: https
********************************************************************************
POST /v1beta1/projects/REDACTED/locations/REDACTED/publishers/google/models/gemini-1.5-flash:computeTokens HTTP/1.1
Accept: */*
Accept-Encoding: gzip, deflate
Accept-Language: *
Connection: keep-alive
Content-Length: 96
Content-Type: application/json
Sec-Fetch-Mode: cors
Test-Name: Client Tests computeTokens Vertex AI should compute tokens with specified parameters


{"contents":[{"parts":[{"text":"The quick brown fox jumps over the lazy dog."}],"role":"user"}]}
60ea11e9fed86d4ccaed270c2425c0d9a8cc06e91ac743e9a78277f3535c1239.resp 769
Status code: 200 
X-Xss-Protection: 0
Content-Type: application/json; charset=UTF-8
Vary: Origin
Vary: X-Origin
Vary: Referer
X-Frame-Options: SAMEORIGIN
X-Content-Type-Options: nosniff
Content-Encoding: gzip
Date: Thu, 24 Jul 2025 03:47:50 GMT
Server: scaffolding on HTTPServer2
Content-Length: 210

{
  "tokensInfo": [
    {
      "tokens": [
        "VGhl",
        "IHF1aWNr",
        "IGJyb3du",
        "IGZveA==",
        "IGp1bXBz",
        "IG92ZXI=",
        "IHRoZQ==",
        "IGxhenk=",
        "IGRvZw==",
        "Lg=="
      ],
      "tokenIds": [
        "651",
        "4320",
        "8426",
        "25341",
        "36271",
        "1163",
        "573",
        "27894",
        "5929",
        "235265"
      ],
      "role": "user"
    }
  ]
}
